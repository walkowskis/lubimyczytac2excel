from selenium import webdriver
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
import time
import openpyxl
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

c_handler = logging.StreamHandler()
c_handler.setLevel(logging.DEBUG)
c_format = logging.Formatter('%(asctime)s - %(levelname)s: %(message)s', datefmt='%H:%M:%S')
c_handler.setFormatter(c_format)
logger.addHandler(c_handler)

f_handler = logging.FileHandler('data_log.log')
f_handler.setLevel(logging.WARNING)
f_format = logging.Formatter('%(asctime)s - %(levelname)s: %(message)s', datefmt='%d-%m-%Y %H:%M:%S')
f_handler.setFormatter(f_format)
logger.addHandler(f_handler)



address = 'https://lubimyczytac.pl/beta/rwdOff'
exceldir = ''
row_from = 
row_to = 
wb = openpyxl.load_workbook(exceldir)
sheet = wb.active

caps = DesiredCapabilities().CHROME
caps["pageLoadStrategy"] = "none"

logger.info('Przygotowanie...')
options = webdriver.ChromeOptions()
options.add_argument('headless')
options.add_argument('desired_capabilities=caps')
options.add_argument('--window-size=1920,1080')
driver = webdriver.Chrome(options=options)
driver.implicitly_wait(10)
driver.get(address)
logger.info('Otwarcie strony.')
time.sleep(5)

driver.switch_to.frame(driver.find_element_by_xpath('//iframe[contains(@name, "TB_iframeContent")]'))
driver.execute_script('toWww()')
driver.switch_to.default_content()
time.sleep(3)
logger.info('Rozpoczęcie wyszukiwania.')

counter = 1
for i in range(row_from, row_to):
    title=sheet.cell(row=i+1,column=2)
    logger.debug('49')
    search = driver.find_element_by_id('searchInput')
    logger.debug('50')
    search.send_keys(title.value)
    logger.debug('52')
    try:
        search.submit()
        logger.debug('55')
    except:
        logger.warning('Time out (%s)!', title.value)
        driver.get(driver.current_url)
    try:
        driver.find_elements_by_css_selector('a.bookTitle')[0].click()
        rating_value = driver.find_element_by_id('rating-value').text
        rating_votes = driver.find_element_by_id('rating-votes').text
        sheet.cell(row=i+1, column=4).value = rating_value
        sheet.cell(row=i+1, column=5).value = rating_votes
        driver.find_element_by_id('aBookDetails').click()
        logger.info('%s. %s - zapisywanie danych:', i, title.value)
        category = []
        category_value = []
        for item in driver.find_elements_by_tag_name('dt'):
            category.append(item.text)
        for item in driver.find_elements_by_tag_name('dd'):
            category_value.append(item.text)

        def scraping(row_no):
            cat = {6: 'kategoria', 7: 'słowa kluczowe', 8: 'liczba stron', 9: 'data wydania', 10: 'sBookDescriptionShort'}
            for n in range(6, 11):
                try:
                    if n == 10:
                        sheet.cell(row=row_no + 1, column=n).value = driver.find_element_by_id(cat.get(n)).text
                    else:
                        sheet.cell(row=row_no + 1, column=n).value = category_value[category.index(cat.get(n))]
                    logger.info('      - %s;', cat.get(n))
                except:
                    logger.info('      - %s - brak;', cat.get(n))

        scraping(i)

        wb.save(exceldir)
        logger.info('Ukończono %s procent.\n', round((i - row_from + 1)*100/(row_to - row_from)))
    except:
        logger.warning('%s - nie znaleziono pozycji!\n', title.value)
        counter += 1
        pass
logger.info('%s z %s pozycji nie zostały odnalezione!', counter-1, (row_to - row_from))
driver.quit()
